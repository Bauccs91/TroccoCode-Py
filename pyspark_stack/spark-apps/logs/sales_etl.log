Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/19 04:49:08 INFO SparkContext: Running Spark version 3.2.1
25/05/19 04:49:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/19 04:49:08 INFO ResourceUtils: ==============================================================
25/05/19 04:49:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/19 04:49:08 INFO ResourceUtils: ==============================================================
25/05/19 04:49:08 INFO SparkContext: Submitted application: SalesETLJob
25/05/19 04:49:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/19 04:49:08 INFO ResourceProfile: Limiting resource is cpu
25/05/19 04:49:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/19 04:49:08 INFO SecurityManager: Changing view acls to: spark
25/05/19 04:49:08 INFO SecurityManager: Changing modify acls to: spark
25/05/19 04:49:08 INFO SecurityManager: Changing view acls groups to: 
25/05/19 04:49:08 INFO SecurityManager: Changing modify acls groups to: 
25/05/19 04:49:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/19 04:49:09 INFO Utils: Successfully started service 'sparkDriver' on port 41547.
25/05/19 04:49:09 INFO SparkEnv: Registering MapOutputTracker
25/05/19 04:49:09 INFO SparkEnv: Registering BlockManagerMaster
25/05/19 04:49:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/19 04:49:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/19 04:49:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/19 04:49:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ae4add64-40b7-4f04-be83-bd1dbee23681
25/05/19 04:49:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/19 04:49:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/19 04:49:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/19 04:49:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b7392c33ae43:4040
25/05/19 04:49:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/19 04:49:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 90 ms (0 ms spent in bootstraps)
25/05/19 04:49:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250519044910-0004
25/05/19 04:49:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250519044910-0004/0 on worker-20250519032032-172.18.0.8-40663 (172.18.0.8:40663) with 8 core(s)
25/05/19 04:49:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20250519044910-0004/0 on hostPort 172.18.0.8:40663 with 8 core(s), 1024.0 MiB RAM
25/05/19 04:49:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37891.
25/05/19 04:49:10 INFO NettyBlockTransferService: Server created on b7392c33ae43:37891
25/05/19 04:49:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/19 04:49:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7392c33ae43, 37891, None)
25/05/19 04:49:10 INFO BlockManagerMasterEndpoint: Registering block manager b7392c33ae43:37891 with 366.3 MiB RAM, BlockManagerId(driver, b7392c33ae43, 37891, None)
25/05/19 04:49:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7392c33ae43, 37891, None)
25/05/19 04:49:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7392c33ae43, 37891, None)
25/05/19 04:49:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250519044910-0004/0 is now RUNNING
25/05/19 04:49:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/19 04:49:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/19 04:49:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/19 04:49:18 INFO InMemoryFileIndex: It took 200 ms to list leaf files for 1 paths.
25/05/19 04:49:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:57008) with ID 0,  ResourceProfileId 0
25/05/19 04:49:18 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.
25/05/19 04:49:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44393 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 44393, None)
25/05/19 04:49:25 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:49:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/19 04:49:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:49:27 INFO CodeGenerator: Code generated in 553.352247 ms
25/05/19 04:49:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/19 04:49:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/19 04:49:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7392c33ae43:37891 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:49:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:49:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:49:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:49:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:49:27 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:49:27 INFO DAGScheduler: Missing parents: List()
25/05/19 04:49:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:49:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/19 04:49:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/19 04:49:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7392c33ae43:37891 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:49:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/19 04:49:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:49:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/19 04:49:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:49:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:44393 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:49:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:44393 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:49:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4517 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:49:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/19 04:49:32 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.863 s
25/05/19 04:49:32 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:49:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/19 04:49:32 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.960905 s
25/05/19 04:49:32 INFO CodeGenerator: Code generated in 27.837737 ms
25/05/19 04:49:32 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:49:32 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:49:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:49:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/19 04:49:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/19 04:49:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7392c33ae43:37891 (size: 32.4 KiB, free: 366.2 MiB)
25/05/19 04:49:32 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:49:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:33 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/05/19 04:49:33 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/05/19 04:49:33 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:49:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:49:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:49:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/19 04:49:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:49:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b7392c33ae43:37891 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:49:33 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/19 04:49:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:33 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/19 04:49:33 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:49:33 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/19 04:49:33 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:49:33 INFO DAGScheduler: Missing parents: List()
25/05/19 04:49:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:49:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/19 04:49:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/19 04:49:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b7392c33ae43:37891 (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:49:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/19 04:49:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:49:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/19 04:49:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:49:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:44393 (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:49:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:44393 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:49:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 418 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:49:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/19 04:49:34 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.504 s
25/05/19 04:49:34 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:49:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/19 04:49:34 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.524430 s
25/05/19 04:49:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:49:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:49:35 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:49:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:49:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:49:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:49:35 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b7392c33ae43:37891 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:49:35 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:44393 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:49:35 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b7392c33ae43:37891 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:49:35 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:44393 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/19 04:49:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7392c33ae43:37891 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:49:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:44393 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:49:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:49:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:49:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/19 04:49:36 INFO CodeGenerator: Code generated in 58.084449 ms
25/05/19 04:49:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/05/19 04:49:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:49:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b7392c33ae43:37891 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:49:36 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:49:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:49:36 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:49:36 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:49:36 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:49:36 INFO DAGScheduler: Missing parents: List()
25/05/19 04:49:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:49:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/19 04:49:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/19 04:49:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on b7392c33ae43:37891 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:49:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/19 04:49:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:49:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/19 04:49:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:49:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:44393 (size: 7.2 KiB, free: 366.3 MiB)
25/05/19 04:49:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:44393 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:49:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 541 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:49:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/19 04:49:36 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.566 s
25/05/19 04:49:36 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:49:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/19 04:49:36 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.576089 s
25/05/19 04:49:37 INFO CodeGenerator: Code generated in 49.69269 ms
25/05/19 04:49:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/19 04:49:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/19 04:49:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on b7392c33ae43:37891 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:49:37 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:49:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:49:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:49:37 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:49:37 INFO CodeGenerator: Code generated in 65.747387 ms
25/05/19 04:49:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/19 04:49:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/19 04:49:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on b7392c33ae43:37891 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:49:37 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:49:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:37 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:49:37 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:49:37 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:49:37 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:49:37 INFO DAGScheduler: Missing parents: List()
25/05/19 04:49:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:49:37 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/19 04:49:37 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/19 04:49:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on b7392c33ae43:37891 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:49:37 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/19 04:49:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:49:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/19 04:49:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:49:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:44393 (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:49:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:44393 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:49:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:44393 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:49:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1104 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:49:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/19 04:49:38 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.179 s
25/05/19 04:49:38 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:49:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/19 04:49:38 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.191020 s
25/05/19 04:49:38 INFO FileFormatWriter: Start to commit write Job 0da430f6-87a3-407f-b59c-cf3b98241ee6.
25/05/19 04:49:38 INFO FileFormatWriter: Write Job 0da430f6-87a3-407f-b59c-cf3b98241ee6 committed. Elapsed time: 139 ms.
25/05/19 04:49:38 INFO FileFormatWriter: Finished processing stats for write job 0da430f6-87a3-407f-b59c-cf3b98241ee6.
25/05/19 04:49:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:49:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:49:38 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:49:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:49:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:49:38 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:49:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:49:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:49:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:49:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:49:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:49:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:49:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on b7392c33ae43:37891 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:49:39 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:49:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:49:39 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:49:39 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:49:39 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:49:39 INFO DAGScheduler: Missing parents: List()
25/05/19 04:49:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on b7392c33ae43:37891 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:49:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/19 04:49:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:49:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/19 04:49:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:44393 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:44393 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:49:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 174 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:49:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/19 04:49:39 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.193 s
25/05/19 04:49:39 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:49:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/19 04:49:39 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.203660 s
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on b7392c33ae43:37891 (size: 250.0 B, free: 366.1 MiB)
25/05/19 04:49:39 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:49:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:49:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:49:39 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on b7392c33ae43:37891 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:49:39 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:49:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:49:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:49:39 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:49:39 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/19 04:49:39 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:49:39 INFO DAGScheduler: Missing parents: List()
25/05/19 04:49:39 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/19 04:49:39 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on b7392c33ae43:37891 (size: 76.0 KiB, free: 365.9 MiB)
25/05/19 04:49:39 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/19 04:49:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:49:39 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/19 04:49:39 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:44393 (size: 76.0 KiB, free: 366.0 MiB)
25/05/19 04:49:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:44393 (size: 250.0 B, free: 366.0 MiB)
25/05/19 04:49:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:44393 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:49:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1600 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:49:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/19 04:49:41 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.643 s
25/05/19 04:49:41 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:49:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/19 04:49:41 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.650993 s
25/05/19 04:49:41 INFO FileFormatWriter: Start to commit write Job 6dbf27dc-cca3-495b-a938-85dcbbdc86a1.
25/05/19 04:49:41 INFO FileFormatWriter: Write Job 6dbf27dc-cca3-495b-a938-85dcbbdc86a1 committed. Elapsed time: 52 ms.
25/05/19 04:49:41 INFO FileFormatWriter: Finished processing stats for write job 6dbf27dc-cca3-495b-a938-85dcbbdc86a1.
Job completed for 2025-01-01
25/05/19 04:49:41 INFO SparkUI: Stopped Spark web UI at http://b7392c33ae43:4040
25/05/19 04:49:41 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/19 04:49:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/19 04:49:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/19 04:49:41 INFO MemoryStore: MemoryStore cleared
25/05/19 04:49:41 INFO BlockManager: BlockManager stopped
25/05/19 04:49:41 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/19 04:49:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/19 04:49:41 INFO SparkContext: Successfully stopped SparkContext
25/05/19 04:49:42 INFO ShutdownHookManager: Shutdown hook called
25/05/19 04:49:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-145a1bf5-be4f-47a3-abe4-505d449cc783
25/05/19 04:49:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-e429dfed-bb43-4712-a93b-d0673ea01dcc/pyspark-c2ef7600-5b65-4e21-96c7-32d273c32bfc
25/05/19 04:49:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-e429dfed-bb43-4712-a93b-d0673ea01dcc
Job completed for 2025-01-01
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/19 04:50:08 INFO SparkContext: Running Spark version 3.2.1
25/05/19 04:50:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/19 04:50:08 INFO ResourceUtils: ==============================================================
25/05/19 04:50:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/19 04:50:08 INFO ResourceUtils: ==============================================================
25/05/19 04:50:08 INFO SparkContext: Submitted application: SalesETLJob
25/05/19 04:50:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/19 04:50:08 INFO ResourceProfile: Limiting resource is cpu
25/05/19 04:50:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/19 04:50:09 INFO SecurityManager: Changing view acls to: spark
25/05/19 04:50:09 INFO SecurityManager: Changing modify acls to: spark
25/05/19 04:50:09 INFO SecurityManager: Changing view acls groups to: 
25/05/19 04:50:09 INFO SecurityManager: Changing modify acls groups to: 
25/05/19 04:50:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/19 04:50:09 INFO Utils: Successfully started service 'sparkDriver' on port 44429.
25/05/19 04:50:09 INFO SparkEnv: Registering MapOutputTracker
25/05/19 04:50:09 INFO SparkEnv: Registering BlockManagerMaster
25/05/19 04:50:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/19 04:50:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/19 04:50:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/19 04:50:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-31a3e40a-73e0-463c-9cba-3332ee18d502
25/05/19 04:50:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/19 04:50:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/19 04:50:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/19 04:50:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b7392c33ae43:4040
25/05/19 04:50:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/19 04:50:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 69 ms (0 ms spent in bootstraps)
25/05/19 04:50:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250519045011-0005
25/05/19 04:50:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250519045011-0005/0 on worker-20250519032032-172.18.0.8-40663 (172.18.0.8:40663) with 8 core(s)
25/05/19 04:50:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250519045011-0005/0 on hostPort 172.18.0.8:40663 with 8 core(s), 1024.0 MiB RAM
25/05/19 04:50:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39377.
25/05/19 04:50:11 INFO NettyBlockTransferService: Server created on b7392c33ae43:39377
25/05/19 04:50:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/19 04:50:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7392c33ae43, 39377, None)
25/05/19 04:50:12 INFO BlockManagerMasterEndpoint: Registering block manager b7392c33ae43:39377 with 366.3 MiB RAM, BlockManagerId(driver, b7392c33ae43, 39377, None)
25/05/19 04:50:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7392c33ae43, 39377, None)
25/05/19 04:50:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7392c33ae43, 39377, None)
25/05/19 04:50:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250519045011-0005/0 is now RUNNING
25/05/19 04:50:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/19 04:50:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/19 04:50:14 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/19 04:50:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:60466) with ID 0,  ResourceProfileId 0
25/05/19 04:50:18 INFO InMemoryFileIndex: It took 185 ms to list leaf files for 1 paths.
25/05/19 04:50:19 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:46455 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 46455, None)
25/05/19 04:50:19 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.
25/05/19 04:50:27 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:50:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/19 04:50:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:50:29 INFO CodeGenerator: Code generated in 702.497364 ms
25/05/19 04:50:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/19 04:50:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/19 04:50:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7392c33ae43:39377 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:50:29 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:50:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:50:29 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:50:29 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:50:29 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:50:29 INFO DAGScheduler: Missing parents: List()
25/05/19 04:50:29 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:50:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/19 04:50:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/19 04:50:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7392c33ae43:39377 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:50:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/19 04:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:50:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/19 04:50:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:50:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:46455 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:50:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:46455 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:50:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5046 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:50:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/19 04:50:35 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.255 s
25/05/19 04:50:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:50:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/19 04:50:35 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.357765 s
25/05/19 04:50:35 INFO CodeGenerator: Code generated in 56.870933 ms
25/05/19 04:50:35 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:50:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:50:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:50:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/19 04:50:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/19 04:50:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7392c33ae43:39377 (size: 32.4 KiB, free: 366.2 MiB)
25/05/19 04:50:35 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:50:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:35 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
25/05/19 04:50:35 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
25/05/19 04:50:35 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:50:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:50:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:50:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/19 04:50:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:50:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b7392c33ae43:39377 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:50:36 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/19 04:50:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:36 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/19 04:50:36 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:50:36 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/19 04:50:36 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:50:36 INFO DAGScheduler: Missing parents: List()
25/05/19 04:50:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:50:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/19 04:50:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/19 04:50:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b7392c33ae43:39377 (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:50:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/19 04:50:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:50:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/19 04:50:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:50:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:46455 (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:50:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:46455 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:50:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 461 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:50:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/19 04:50:36 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.580 s
25/05/19 04:50:36 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:50:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/19 04:50:36 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.611092 s
25/05/19 04:50:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:50:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:50:38 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:50:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:50:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:50:38 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:50:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:50:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:50:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/19 04:50:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7392c33ae43:39377 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:46455 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b7392c33ae43:39377 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:46455 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b7392c33ae43:39377 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:46455 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:50:38 INFO CodeGenerator: Code generated in 44.388453 ms
25/05/19 04:50:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/05/19 04:50:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b7392c33ae43:39377 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:50:38 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:50:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:50:38 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:50:38 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:50:38 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:50:38 INFO DAGScheduler: Missing parents: List()
25/05/19 04:50:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:50:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/19 04:50:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/19 04:50:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on b7392c33ae43:39377 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:50:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/19 04:50:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:50:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/19 04:50:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:50:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:46455 (size: 7.2 KiB, free: 366.3 MiB)
25/05/19 04:50:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:46455 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:50:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 430 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:50:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/19 04:50:39 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.456 s
25/05/19 04:50:39 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:50:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/19 04:50:39 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.463743 s
25/05/19 04:50:39 INFO CodeGenerator: Code generated in 30.700505 ms
25/05/19 04:50:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/19 04:50:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/19 04:50:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on b7392c33ae43:39377 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:50:39 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:50:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:50:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:50:39 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:50:39 INFO CodeGenerator: Code generated in 52.92932 ms
25/05/19 04:50:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/19 04:50:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/19 04:50:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on b7392c33ae43:39377 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:50:39 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:50:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:39 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:50:39 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:50:39 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:50:39 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:50:39 INFO DAGScheduler: Missing parents: List()
25/05/19 04:50:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:50:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/19 04:50:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/19 04:50:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on b7392c33ae43:39377 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:50:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/19 04:50:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:50:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/19 04:50:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:50:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:46455 (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:50:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:46455 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:50:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:46455 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:50:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 996 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:50:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/19 04:50:40 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.070 s
25/05/19 04:50:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:50:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/19 04:50:40 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.084733 s
25/05/19 04:50:40 INFO FileFormatWriter: Start to commit write Job 2cfd0ec5-3e8e-4193-9428-55ce92de0123.
25/05/19 04:50:41 INFO FileFormatWriter: Write Job 2cfd0ec5-3e8e-4193-9428-55ce92de0123 committed. Elapsed time: 131 ms.
25/05/19 04:50:41 INFO FileFormatWriter: Finished processing stats for write job 2cfd0ec5-3e8e-4193-9428-55ce92de0123.
25/05/19 04:50:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:50:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:50:41 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:50:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:50:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:50:41 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:50:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:50:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:50:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:50:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:50:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:50:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:50:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:50:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/19 04:50:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/19 04:50:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on b7392c33ae43:39377 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:50:41 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:50:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:50:41 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:50:41 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:50:41 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:50:41 INFO DAGScheduler: Missing parents: List()
25/05/19 04:50:41 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:50:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/19 04:50:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/19 04:50:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on b7392c33ae43:39377 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:50:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/19 04:50:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:50:41 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/19 04:50:41 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:50:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:46455 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:50:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:46455 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:50:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 283 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:50:41 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/19 04:50:41 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.309 s
25/05/19 04:50:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:50:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/19 04:50:41 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.326679 s
25/05/19 04:50:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/19 04:50:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/19 04:50:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on b7392c33ae43:39377 (size: 250.0 B, free: 366.1 MiB)
25/05/19 04:50:42 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:50:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:50:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:50:42 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:50:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/19 04:50:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/19 04:50:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on b7392c33ae43:39377 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:50:42 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:50:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:50:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:50:42 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:50:42 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/19 04:50:42 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:50:42 INFO DAGScheduler: Missing parents: List()
25/05/19 04:50:42 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:50:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/19 04:50:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/19 04:50:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on b7392c33ae43:39377 (size: 76.0 KiB, free: 365.9 MiB)
25/05/19 04:50:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/19 04:50:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:50:42 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/19 04:50:42 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:50:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:46455 (size: 76.0 KiB, free: 366.0 MiB)
25/05/19 04:50:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:46455 (size: 250.0 B, free: 366.0 MiB)
25/05/19 04:50:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:46455 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:50:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2834 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:50:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/19 04:50:45 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 2.910 s
25/05/19 04:50:45 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:50:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/19 04:50:45 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 2.919158 s
25/05/19 04:50:45 INFO FileFormatWriter: Start to commit write Job fef29517-52b4-45db-9ee0-5e3fc781e9c9.
25/05/19 04:50:45 INFO FileFormatWriter: Write Job fef29517-52b4-45db-9ee0-5e3fc781e9c9 committed. Elapsed time: 73 ms.
25/05/19 04:50:45 INFO FileFormatWriter: Finished processing stats for write job fef29517-52b4-45db-9ee0-5e3fc781e9c9.
Job completed for 2025-01-01
25/05/19 04:50:45 INFO SparkUI: Stopped Spark web UI at http://b7392c33ae43:4040
25/05/19 04:50:45 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/19 04:50:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/19 04:50:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/19 04:50:45 INFO MemoryStore: MemoryStore cleared
25/05/19 04:50:45 INFO BlockManager: BlockManager stopped
25/05/19 04:50:45 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/19 04:50:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/19 04:50:45 INFO SparkContext: Successfully stopped SparkContext
25/05/19 04:50:45 INFO ShutdownHookManager: Shutdown hook called
25/05/19 04:50:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-671d7778-5edf-4706-a81b-01238b4437c7
25/05/19 04:50:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-3282762d-c003-4b9d-b3e4-4ea12621b6fb/pyspark-db0bc88b-3691-4328-8236-51ffa58ec799
25/05/19 04:50:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-3282762d-c003-4b9d-b3e4-4ea12621b6fb
Job completed for 2025-01-01
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/19 04:51:07 INFO SparkContext: Running Spark version 3.2.1
25/05/19 04:51:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/19 04:51:08 INFO ResourceUtils: ==============================================================
25/05/19 04:51:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/19 04:51:08 INFO ResourceUtils: ==============================================================
25/05/19 04:51:08 INFO SparkContext: Submitted application: SalesETLJob
25/05/19 04:51:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/19 04:51:08 INFO ResourceProfile: Limiting resource is cpu
25/05/19 04:51:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/19 04:51:08 INFO SecurityManager: Changing view acls to: spark
25/05/19 04:51:08 INFO SecurityManager: Changing modify acls to: spark
25/05/19 04:51:08 INFO SecurityManager: Changing view acls groups to: 
25/05/19 04:51:08 INFO SecurityManager: Changing modify acls groups to: 
25/05/19 04:51:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/19 04:51:09 INFO Utils: Successfully started service 'sparkDriver' on port 33537.
25/05/19 04:51:09 INFO SparkEnv: Registering MapOutputTracker
25/05/19 04:51:09 INFO SparkEnv: Registering BlockManagerMaster
25/05/19 04:51:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/19 04:51:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/19 04:51:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/19 04:51:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-16d1a874-9ef9-4133-97ef-599b9940191b
25/05/19 04:51:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/19 04:51:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/19 04:51:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/19 04:51:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b7392c33ae43:4040
25/05/19 04:51:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/19 04:51:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 123 ms (0 ms spent in bootstraps)
25/05/19 04:51:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250519045111-0006
25/05/19 04:51:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250519045111-0006/0 on worker-20250519032032-172.18.0.8-40663 (172.18.0.8:40663) with 8 core(s)
25/05/19 04:51:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250519045111-0006/0 on hostPort 172.18.0.8:40663 with 8 core(s), 1024.0 MiB RAM
25/05/19 04:51:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34397.
25/05/19 04:51:11 INFO NettyBlockTransferService: Server created on b7392c33ae43:34397
25/05/19 04:51:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/19 04:51:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7392c33ae43, 34397, None)
25/05/19 04:51:12 INFO BlockManagerMasterEndpoint: Registering block manager b7392c33ae43:34397 with 366.3 MiB RAM, BlockManagerId(driver, b7392c33ae43, 34397, None)
25/05/19 04:51:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7392c33ae43, 34397, None)
25/05/19 04:51:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7392c33ae43, 34397, None)
25/05/19 04:51:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250519045111-0006/0 is now RUNNING
25/05/19 04:51:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/19 04:51:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/19 04:51:14 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/19 04:51:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:43594) with ID 0,  ResourceProfileId 0
25/05/19 04:51:22 INFO InMemoryFileIndex: It took 602 ms to list leaf files for 1 paths.
25/05/19 04:51:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42071 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 42071, None)
25/05/19 04:51:23 INFO InMemoryFileIndex: It took 27 ms to list leaf files for 1 paths.
25/05/19 04:51:32 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:51:32 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/19 04:51:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:51:33 INFO CodeGenerator: Code generated in 651.29926 ms
25/05/19 04:51:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/19 04:51:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/19 04:51:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7392c33ae43:34397 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:51:33 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:51:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:51:34 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:51:34 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:51:34 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:51:34 INFO DAGScheduler: Missing parents: List()
25/05/19 04:51:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:51:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/19 04:51:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/19 04:51:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7392c33ae43:34397 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:51:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/19 04:51:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:51:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/19 04:51:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:51:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:42071 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:51:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:42071 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:51:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5227 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:51:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/19 04:51:39 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.449 s
25/05/19 04:51:39 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:51:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/19 04:51:39 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.536633 s
25/05/19 04:51:39 INFO CodeGenerator: Code generated in 19.343835 ms
25/05/19 04:51:40 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:51:40 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:51:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:51:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/19 04:51:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/19 04:51:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7392c33ae43:34397 (size: 32.4 KiB, free: 366.2 MiB)
25/05/19 04:51:40 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:51:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:40 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/05/19 04:51:40 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/05/19 04:51:40 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:51:40 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:51:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:51:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/19 04:51:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:51:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b7392c33ae43:34397 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:51:40 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/19 04:51:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:40 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/19 04:51:40 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:51:40 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/19 04:51:40 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:51:40 INFO DAGScheduler: Missing parents: List()
25/05/19 04:51:40 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:51:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/19 04:51:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/19 04:51:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b7392c33ae43:34397 (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:51:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/19 04:51:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:51:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/19 04:51:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:51:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:42071 (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:51:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:42071 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:51:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 396 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:51:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/19 04:51:41 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.450 s
25/05/19 04:51:41 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:51:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/19 04:51:41 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.470659 s
25/05/19 04:51:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:51:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:51:42 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:51:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:51:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:51:42 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:51:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:51:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:51:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/19 04:51:43 INFO CodeGenerator: Code generated in 49.283348 ms
25/05/19 04:51:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/05/19 04:51:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/05/19 04:51:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b7392c33ae43:34397 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:51:43 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:51:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7392c33ae43:34397 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:51:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:42071 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:51:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:42071 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/19 04:51:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b7392c33ae43:34397 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:51:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:51:43 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:51:43 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:51:43 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:51:43 INFO DAGScheduler: Missing parents: List()
25/05/19 04:51:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:51:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/19 04:51:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/19 04:51:43 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b7392c33ae43:34397 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:51:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on b7392c33ae43:34397 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:51:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/19 04:51:43 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:42071 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:51:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:51:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/19 04:51:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:51:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:42071 (size: 7.2 KiB, free: 366.3 MiB)
25/05/19 04:51:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:42071 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:51:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 654 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:51:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/19 04:51:44 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.687 s
25/05/19 04:51:44 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:51:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/19 04:51:44 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.707838 s
25/05/19 04:51:44 INFO CodeGenerator: Code generated in 26.902626 ms
25/05/19 04:51:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/19 04:51:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/19 04:51:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on b7392c33ae43:34397 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:51:44 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:51:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:51:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:51:44 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:51:44 INFO CodeGenerator: Code generated in 80.027508 ms
25/05/19 04:51:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/19 04:51:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/19 04:51:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on b7392c33ae43:34397 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:51:44 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:51:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:44 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:51:44 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:51:44 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:51:44 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:51:44 INFO DAGScheduler: Missing parents: List()
25/05/19 04:51:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:51:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/19 04:51:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/19 04:51:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on b7392c33ae43:34397 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:51:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/19 04:51:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:51:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/19 04:51:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:51:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:42071 (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:51:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42071 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:51:46 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42071 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:51:46 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1585 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:51:46 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/19 04:51:46 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.754 s
25/05/19 04:51:46 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/19 04:51:46 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.785184 s
25/05/19 04:51:46 INFO FileFormatWriter: Start to commit write Job 667a0505-d6a8-40a6-8387-cbf5bfde26ac.
25/05/19 04:51:46 INFO FileFormatWriter: Write Job 667a0505-d6a8-40a6-8387-cbf5bfde26ac committed. Elapsed time: 160 ms.
25/05/19 04:51:46 INFO FileFormatWriter: Finished processing stats for write job 667a0505-d6a8-40a6-8387-cbf5bfde26ac.
25/05/19 04:51:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:51:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:51:47 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:51:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:51:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:51:47 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:51:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:51:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:51:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:51:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:51:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:51:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:51:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on b7392c33ae43:34397 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:51:47 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:51:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:51:47 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:51:47 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:51:47 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:51:47 INFO DAGScheduler: Missing parents: List()
25/05/19 04:51:47 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on b7392c33ae43:34397 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:51:47 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/19 04:51:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:51:47 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/19 04:51:47 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:42071 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:42071 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:51:47 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 207 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:51:47 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/19 04:51:47 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.238 s
25/05/19 04:51:47 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:51:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/19 04:51:47 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.253490 s
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on b7392c33ae43:34397 (size: 250.0 B, free: 366.1 MiB)
25/05/19 04:51:47 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:51:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:51:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:51:47 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on b7392c33ae43:34397 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:51:47 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:51:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:51:47 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:51:47 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:51:47 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/19 04:51:47 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:51:47 INFO DAGScheduler: Missing parents: List()
25/05/19 04:51:47 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/19 04:51:47 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on b7392c33ae43:34397 (size: 76.0 KiB, free: 365.9 MiB)
25/05/19 04:51:47 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/19 04:51:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:51:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/19 04:51:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:42071 (size: 76.0 KiB, free: 366.0 MiB)
25/05/19 04:51:47 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:42071 (size: 250.0 B, free: 366.0 MiB)
25/05/19 04:51:48 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:42071 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:51:49 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1540 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:51:49 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/19 04:51:49 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.585 s
25/05/19 04:51:49 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:51:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/19 04:51:49 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.592718 s
25/05/19 04:51:49 INFO FileFormatWriter: Start to commit write Job 01b86ecc-fc44-4f1b-9512-ccbe3348101f.
25/05/19 04:51:49 INFO FileFormatWriter: Write Job 01b86ecc-fc44-4f1b-9512-ccbe3348101f committed. Elapsed time: 49 ms.
25/05/19 04:51:49 INFO FileFormatWriter: Finished processing stats for write job 01b86ecc-fc44-4f1b-9512-ccbe3348101f.
Job completed for 2025-01-01
25/05/19 04:51:49 INFO SparkUI: Stopped Spark web UI at http://b7392c33ae43:4040
25/05/19 04:51:49 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/19 04:51:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/19 04:51:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/19 04:51:49 INFO MemoryStore: MemoryStore cleared
25/05/19 04:51:49 INFO BlockManager: BlockManager stopped
25/05/19 04:51:49 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/19 04:51:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/19 04:51:49 INFO SparkContext: Successfully stopped SparkContext
25/05/19 04:51:49 INFO ShutdownHookManager: Shutdown hook called
25/05/19 04:51:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-9c2a8e8f-98c7-48b4-9bc5-81f9fb73462d
25/05/19 04:51:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-9c2a8e8f-98c7-48b4-9bc5-81f9fb73462d/pyspark-dc31782e-2352-433f-b5ae-43036fd5e8de
25/05/19 04:51:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-4301d406-6574-4097-bf72-0c6e9bceb71d
Job completed for 2025-01-01
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/19 04:52:08 INFO SparkContext: Running Spark version 3.2.1
25/05/19 04:52:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/19 04:52:08 INFO ResourceUtils: ==============================================================
25/05/19 04:52:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/19 04:52:08 INFO ResourceUtils: ==============================================================
25/05/19 04:52:08 INFO SparkContext: Submitted application: SalesETLJob
25/05/19 04:52:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/19 04:52:08 INFO ResourceProfile: Limiting resource is cpu
25/05/19 04:52:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/19 04:52:08 INFO SecurityManager: Changing view acls to: spark
25/05/19 04:52:08 INFO SecurityManager: Changing modify acls to: spark
25/05/19 04:52:08 INFO SecurityManager: Changing view acls groups to: 
25/05/19 04:52:08 INFO SecurityManager: Changing modify acls groups to: 
25/05/19 04:52:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/19 04:52:09 INFO Utils: Successfully started service 'sparkDriver' on port 44451.
25/05/19 04:52:09 INFO SparkEnv: Registering MapOutputTracker
25/05/19 04:52:09 INFO SparkEnv: Registering BlockManagerMaster
25/05/19 04:52:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/19 04:52:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/19 04:52:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/19 04:52:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8631c02c-e0b8-4e04-ad40-6a4677938d36
25/05/19 04:52:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/19 04:52:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/19 04:52:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/19 04:52:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b7392c33ae43:4040
25/05/19 04:52:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/19 04:52:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 70 ms (0 ms spent in bootstraps)
25/05/19 04:52:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250519045211-0007
25/05/19 04:52:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250519045211-0007/0 on worker-20250519032032-172.18.0.8-40663 (172.18.0.8:40663) with 8 core(s)
25/05/19 04:52:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250519045211-0007/0 on hostPort 172.18.0.8:40663 with 8 core(s), 1024.0 MiB RAM
25/05/19 04:52:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32771.
25/05/19 04:52:11 INFO NettyBlockTransferService: Server created on b7392c33ae43:32771
25/05/19 04:52:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/19 04:52:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7392c33ae43, 32771, None)
25/05/19 04:52:11 INFO BlockManagerMasterEndpoint: Registering block manager b7392c33ae43:32771 with 366.3 MiB RAM, BlockManagerId(driver, b7392c33ae43, 32771, None)
25/05/19 04:52:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7392c33ae43, 32771, None)
25/05/19 04:52:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7392c33ae43, 32771, None)
25/05/19 04:52:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250519045211-0007/0 is now RUNNING
25/05/19 04:52:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/19 04:52:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/19 04:52:15 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/19 04:52:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:43496) with ID 0,  ResourceProfileId 0
25/05/19 04:52:20 INFO InMemoryFileIndex: It took 326 ms to list leaf files for 1 paths.
25/05/19 04:52:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33131 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 33131, None)
25/05/19 04:52:21 INFO InMemoryFileIndex: It took 21 ms to list leaf files for 1 paths.
25/05/19 04:52:27 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:52:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/19 04:52:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:52:28 INFO CodeGenerator: Code generated in 501.077407 ms
25/05/19 04:52:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/19 04:52:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/19 04:52:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7392c33ae43:32771 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:52:28 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:52:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:52:29 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:52:29 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:52:29 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:52:29 INFO DAGScheduler: Missing parents: List()
25/05/19 04:52:29 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:52:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/19 04:52:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/19 04:52:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7392c33ae43:32771 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:52:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/19 04:52:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:52:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/19 04:52:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:52:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:33131 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:52:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:33131 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:52:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 6348 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:52:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/19 04:52:35 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 6.538 s
25/05/19 04:52:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:52:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/19 04:52:35 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.501868 s
25/05/19 04:52:35 INFO CodeGenerator: Code generated in 36.005597 ms
25/05/19 04:52:35 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:52:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:52:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:52:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/19 04:52:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/19 04:52:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7392c33ae43:32771 (size: 32.4 KiB, free: 366.2 MiB)
25/05/19 04:52:36 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:52:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:36 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.
25/05/19 04:52:36 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
25/05/19 04:52:36 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:52:36 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:52:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:52:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/19 04:52:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:52:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b7392c33ae43:32771 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:52:36 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/19 04:52:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:36 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/19 04:52:36 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:52:36 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/19 04:52:36 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:52:36 INFO DAGScheduler: Missing parents: List()
25/05/19 04:52:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:52:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/19 04:52:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/19 04:52:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b7392c33ae43:32771 (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:52:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/19 04:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:52:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/19 04:52:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:52:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:33131 (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:52:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:33131 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:52:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 503 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:52:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/19 04:52:37 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.561 s
25/05/19 04:52:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:52:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/19 04:52:37 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.581792 s
25/05/19 04:52:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b7392c33ae43:32771 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:52:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:33131 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/19 04:52:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7392c33ae43:32771 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:52:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:33131 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:52:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b7392c33ae43:32771 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:52:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:33131 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:52:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:52:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:52:38 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:52:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:52:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:52:38 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:52:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:52:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:52:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/19 04:52:39 INFO CodeGenerator: Code generated in 53.450202 ms
25/05/19 04:52:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/05/19 04:52:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:52:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b7392c33ae43:32771 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:52:39 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:52:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:52:39 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:52:39 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:52:39 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:52:39 INFO DAGScheduler: Missing parents: List()
25/05/19 04:52:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:52:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/19 04:52:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/19 04:52:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on b7392c33ae43:32771 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:52:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/19 04:52:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:52:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/19 04:52:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:52:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:33131 (size: 7.2 KiB, free: 366.3 MiB)
25/05/19 04:52:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:33131 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:52:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 613 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:52:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/19 04:52:40 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.650 s
25/05/19 04:52:40 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:52:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/19 04:52:40 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.664805 s
25/05/19 04:52:40 INFO CodeGenerator: Code generated in 34.009004 ms
25/05/19 04:52:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/19 04:52:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/19 04:52:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on b7392c33ae43:32771 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:52:40 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:52:40 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:52:40 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:52:40 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:52:40 INFO CodeGenerator: Code generated in 61.503524 ms
25/05/19 04:52:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/19 04:52:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/19 04:52:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on b7392c33ae43:32771 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:52:40 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:52:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:52:40 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:52:40 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:52:40 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:52:40 INFO DAGScheduler: Missing parents: List()
25/05/19 04:52:40 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:52:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/19 04:52:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/19 04:52:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on b7392c33ae43:32771 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:52:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/19 04:52:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:52:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/19 04:52:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:52:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:33131 (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:52:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:33131 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:52:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:33131 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:52:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 869 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:52:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/19 04:52:41 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.953 s
25/05/19 04:52:41 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:52:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/19 04:52:41 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.970471 s
25/05/19 04:52:41 INFO FileFormatWriter: Start to commit write Job dadb212e-e1db-4811-bf81-73e6380ad17b.
25/05/19 04:52:41 INFO FileFormatWriter: Write Job dadb212e-e1db-4811-bf81-73e6380ad17b committed. Elapsed time: 142 ms.
25/05/19 04:52:41 INFO FileFormatWriter: Finished processing stats for write job dadb212e-e1db-4811-bf81-73e6380ad17b.
25/05/19 04:52:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:52:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:52:42 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:52:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:52:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:52:42 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:52:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:52:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:52:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:52:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:52:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:52:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:52:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on b7392c33ae43:32771 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:52:42 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:52:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:42 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:52:42 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:52:42 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:52:42 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:52:42 INFO DAGScheduler: Missing parents: List()
25/05/19 04:52:42 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on b7392c33ae43:32771 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:52:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/19 04:52:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:52:42 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/19 04:52:42 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:33131 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:33131 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:52:42 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 105 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:52:42 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/19 04:52:42 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.123 s
25/05/19 04:52:42 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:52:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/19 04:52:42 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.129848 s
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on b7392c33ae43:32771 (size: 250.0 B, free: 366.1 MiB)
25/05/19 04:52:42 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:52:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:52:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:52:42 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on b7392c33ae43:32771 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:52:42 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:52:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:52:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:52:42 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:52:42 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/19 04:52:42 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:52:42 INFO DAGScheduler: Missing parents: List()
25/05/19 04:52:42 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/19 04:52:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on b7392c33ae43:32771 (size: 76.0 KiB, free: 365.9 MiB)
25/05/19 04:52:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/19 04:52:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:52:42 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/19 04:52:42 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:33131 (size: 76.0 KiB, free: 366.0 MiB)
25/05/19 04:52:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:33131 (size: 250.0 B, free: 366.0 MiB)
25/05/19 04:52:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:33131 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:52:44 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1578 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:52:44 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/19 04:52:44 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.632 s
25/05/19 04:52:44 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:52:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/19 04:52:44 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.638065 s
25/05/19 04:52:44 INFO FileFormatWriter: Start to commit write Job 6af05e37-d7a1-46c0-be2b-0e60eb1a608f.
25/05/19 04:52:44 INFO FileFormatWriter: Write Job 6af05e37-d7a1-46c0-be2b-0e60eb1a608f committed. Elapsed time: 34 ms.
25/05/19 04:52:44 INFO FileFormatWriter: Finished processing stats for write job 6af05e37-d7a1-46c0-be2b-0e60eb1a608f.
Job completed for 2025-01-01
25/05/19 04:52:44 INFO SparkUI: Stopped Spark web UI at http://b7392c33ae43:4040
25/05/19 04:52:44 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/19 04:52:44 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/19 04:52:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/19 04:52:44 INFO MemoryStore: MemoryStore cleared
25/05/19 04:52:44 INFO BlockManager: BlockManager stopped
25/05/19 04:52:44 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/19 04:52:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/19 04:52:44 INFO SparkContext: Successfully stopped SparkContext
25/05/19 04:52:44 INFO ShutdownHookManager: Shutdown hook called
25/05/19 04:52:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe00477c-cb0b-4413-81bd-f9e6c79b4c0c/pyspark-a9b003c6-58d8-45a2-b1f6-ee25ad8d38da
25/05/19 04:52:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe00477c-cb0b-4413-81bd-f9e6c79b4c0c
25/05/19 04:52:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-a1a7d9ae-f196-42b4-84b3-7c9642060a87
Job completed for 2025-01-01
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/19 04:53:06 INFO SparkContext: Running Spark version 3.2.1
25/05/19 04:53:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/19 04:53:06 INFO ResourceUtils: ==============================================================
25/05/19 04:53:06 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/19 04:53:06 INFO ResourceUtils: ==============================================================
25/05/19 04:53:06 INFO SparkContext: Submitted application: SalesETLJob
25/05/19 04:53:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/19 04:53:06 INFO ResourceProfile: Limiting resource is cpu
25/05/19 04:53:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/19 04:53:06 INFO SecurityManager: Changing view acls to: spark
25/05/19 04:53:06 INFO SecurityManager: Changing modify acls to: spark
25/05/19 04:53:06 INFO SecurityManager: Changing view acls groups to: 
25/05/19 04:53:06 INFO SecurityManager: Changing modify acls groups to: 
25/05/19 04:53:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/19 04:53:07 INFO Utils: Successfully started service 'sparkDriver' on port 46659.
25/05/19 04:53:07 INFO SparkEnv: Registering MapOutputTracker
25/05/19 04:53:07 INFO SparkEnv: Registering BlockManagerMaster
25/05/19 04:53:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/19 04:53:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/19 04:53:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/19 04:53:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2a2c2a60-edaf-4076-a9ca-f25439f6f99b
25/05/19 04:53:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/19 04:53:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/19 04:53:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/19 04:53:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b7392c33ae43:4040
25/05/19 04:53:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/19 04:53:09 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 47 ms (0 ms spent in bootstraps)
25/05/19 04:53:09 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250519045309-0008
25/05/19 04:53:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44137.
25/05/19 04:53:09 INFO NettyBlockTransferService: Server created on b7392c33ae43:44137
25/05/19 04:53:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250519045309-0008/0 on worker-20250519032032-172.18.0.8-40663 (172.18.0.8:40663) with 8 core(s)
25/05/19 04:53:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20250519045309-0008/0 on hostPort 172.18.0.8:40663 with 8 core(s), 1024.0 MiB RAM
25/05/19 04:53:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/19 04:53:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7392c33ae43, 44137, None)
25/05/19 04:53:09 INFO BlockManagerMasterEndpoint: Registering block manager b7392c33ae43:44137 with 366.3 MiB RAM, BlockManagerId(driver, b7392c33ae43, 44137, None)
25/05/19 04:53:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7392c33ae43, 44137, None)
25/05/19 04:53:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7392c33ae43, 44137, None)
25/05/19 04:53:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250519045309-0008/0 is now RUNNING
25/05/19 04:53:09 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/19 04:53:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/19 04:53:10 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/19 04:53:12 INFO InMemoryFileIndex: It took 87 ms to list leaf files for 1 paths.
25/05/19 04:53:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:49378) with ID 0,  ResourceProfileId 0
25/05/19 04:53:12 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/05/19 04:53:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42997 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 42997, None)
25/05/19 04:53:15 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:53:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/19 04:53:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:53:17 INFO CodeGenerator: Code generated in 619.238739 ms
25/05/19 04:53:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/19 04:53:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/19 04:53:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7392c33ae43:44137 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:53:17 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:53:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:17 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:53:17 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:53:17 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:53:17 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:53:17 INFO DAGScheduler: Missing parents: List()
25/05/19 04:53:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:53:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/19 04:53:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/19 04:53:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7392c33ae43:44137 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:53:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/19 04:53:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:53:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/19 04:53:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:53:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:42997 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:53:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:42997 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:53:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3490 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:53:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/19 04:53:21 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.728 s
25/05/19 04:53:21 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:53:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/19 04:53:21 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.825098 s
25/05/19 04:53:21 INFO CodeGenerator: Code generated in 20.740743 ms
25/05/19 04:53:21 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:53:21 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:53:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:53:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/19 04:53:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/19 04:53:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7392c33ae43:44137 (size: 32.4 KiB, free: 366.2 MiB)
25/05/19 04:53:21 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:53:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:21 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/05/19 04:53:21 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/05/19 04:53:21 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:53:21 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:53:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:53:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/19 04:53:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:53:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b7392c33ae43:44137 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:53:21 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/19 04:53:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:22 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/19 04:53:22 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:53:22 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/19 04:53:22 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:53:22 INFO DAGScheduler: Missing parents: List()
25/05/19 04:53:22 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:53:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/19 04:53:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/19 04:53:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b7392c33ae43:44137 (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:53:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/19 04:53:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:53:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/19 04:53:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:53:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:42997 (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:53:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:42997 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:53:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 423 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:53:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/19 04:53:22 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.470 s
25/05/19 04:53:22 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:53:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/19 04:53:22 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.482921 s
25/05/19 04:53:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7392c33ae43:44137 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:53:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:42997 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:53:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:42997 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/19 04:53:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b7392c33ae43:44137 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:53:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b7392c33ae43:44137 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:53:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:42997 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:53:23 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:53:23 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:53:23 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:53:23 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:53:23 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:53:23 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:53:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:53:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:53:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/19 04:53:23 INFO CodeGenerator: Code generated in 20.195835 ms
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b7392c33ae43:44137 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:53:24 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:53:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:53:24 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:53:24 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:53:24 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:53:24 INFO DAGScheduler: Missing parents: List()
25/05/19 04:53:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on b7392c33ae43:44137 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:53:24 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/19 04:53:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:53:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/19 04:53:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:42997 (size: 7.2 KiB, free: 366.3 MiB)
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:42997 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:53:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 304 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:53:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/19 04:53:24 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.323 s
25/05/19 04:53:24 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:53:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/19 04:53:24 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.329660 s
25/05/19 04:53:24 INFO CodeGenerator: Code generated in 15.266932 ms
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on b7392c33ae43:44137 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:53:24 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:53:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:53:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:53:24 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:53:24 INFO CodeGenerator: Code generated in 36.621653 ms
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on b7392c33ae43:44137 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:53:24 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:53:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:53:24 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:53:24 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:53:24 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:53:24 INFO DAGScheduler: Missing parents: List()
25/05/19 04:53:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/19 04:53:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on b7392c33ae43:44137 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:53:24 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/19 04:53:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:53:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/19 04:53:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:53:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:42997 (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42997 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42997 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:53:25 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 677 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:53:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/19 04:53:25 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.734 s
25/05/19 04:53:25 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:53:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/19 04:53:25 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.743781 s
25/05/19 04:53:25 INFO FileFormatWriter: Start to commit write Job 38f7c79c-513c-4b93-a249-c14899f14213.
25/05/19 04:53:25 INFO FileFormatWriter: Write Job 38f7c79c-513c-4b93-a249-c14899f14213 committed. Elapsed time: 111 ms.
25/05/19 04:53:25 INFO FileFormatWriter: Finished processing stats for write job 38f7c79c-513c-4b93-a249-c14899f14213.
25/05/19 04:53:25 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:53:25 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:53:25 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:53:25 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:53:25 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:53:25 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:53:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:53:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:53:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:53:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:53:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:53:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:53:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on b7392c33ae43:44137 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:53:25 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:53:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:25 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:53:25 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:53:25 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:53:25 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:53:25 INFO DAGScheduler: Missing parents: List()
25/05/19 04:53:25 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on b7392c33ae43:44137 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:53:25 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/19 04:53:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:53:25 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/19 04:53:25 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:42997 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:42997 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:53:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 76 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:53:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/19 04:53:25 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.086 s
25/05/19 04:53:25 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:53:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/19 04:53:25 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.096645 s
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on b7392c33ae43:44137 (size: 250.0 B, free: 366.1 MiB)
25/05/19 04:53:25 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:53:25 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:53:25 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:53:25 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/19 04:53:25 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/19 04:53:25 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on b7392c33ae43:44137 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:53:25 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:53:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:53:26 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:53:26 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:53:26 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/19 04:53:26 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:53:26 INFO DAGScheduler: Missing parents: List()
25/05/19 04:53:26 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:53:26 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/19 04:53:26 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/19 04:53:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on b7392c33ae43:44137 (size: 76.0 KiB, free: 365.9 MiB)
25/05/19 04:53:26 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/19 04:53:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:53:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/19 04:53:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:53:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:42997 (size: 76.0 KiB, free: 366.0 MiB)
25/05/19 04:53:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:42997 (size: 250.0 B, free: 366.0 MiB)
25/05/19 04:53:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:42997 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:53:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1049 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:53:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/19 04:53:27 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.086 s
25/05/19 04:53:27 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:53:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/19 04:53:27 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.091269 s
25/05/19 04:53:27 INFO FileFormatWriter: Start to commit write Job dcb363c4-d496-4e73-9db4-38ced2588a4c.
25/05/19 04:53:27 INFO FileFormatWriter: Write Job dcb363c4-d496-4e73-9db4-38ced2588a4c committed. Elapsed time: 35 ms.
25/05/19 04:53:27 INFO FileFormatWriter: Finished processing stats for write job dcb363c4-d496-4e73-9db4-38ced2588a4c.
Job completed for 2025-01-01
25/05/19 04:53:27 INFO SparkUI: Stopped Spark web UI at http://b7392c33ae43:4040
25/05/19 04:53:27 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/19 04:53:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/19 04:53:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/19 04:53:27 INFO MemoryStore: MemoryStore cleared
25/05/19 04:53:27 INFO BlockManager: BlockManager stopped
25/05/19 04:53:27 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/19 04:53:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/19 04:53:27 INFO SparkContext: Successfully stopped SparkContext
25/05/19 04:53:27 INFO ShutdownHookManager: Shutdown hook called
25/05/19 04:53:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9008047-88f4-400b-a90c-8667029a115c
25/05/19 04:53:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-f18907c8-0fe6-4619-a4a5-bb5a8ea0c95d
25/05/19 04:53:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-f18907c8-0fe6-4619-a4a5-bb5a8ea0c95d/pyspark-0c44342f-c381-44d3-bb21-bf040f2469a6
Job completed for 2025-01-01
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/19 04:54:46 INFO SparkContext: Running Spark version 3.2.1
25/05/19 04:54:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/19 04:54:46 INFO ResourceUtils: ==============================================================
25/05/19 04:54:46 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/19 04:54:46 INFO ResourceUtils: ==============================================================
25/05/19 04:54:46 INFO SparkContext: Submitted application: SalesETLJob
25/05/19 04:54:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/19 04:54:46 INFO ResourceProfile: Limiting resource is cpu
25/05/19 04:54:46 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/19 04:54:46 INFO SecurityManager: Changing view acls to: spark
25/05/19 04:54:46 INFO SecurityManager: Changing modify acls to: spark
25/05/19 04:54:46 INFO SecurityManager: Changing view acls groups to: 
25/05/19 04:54:46 INFO SecurityManager: Changing modify acls groups to: 
25/05/19 04:54:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/19 04:54:46 INFO Utils: Successfully started service 'sparkDriver' on port 41953.
25/05/19 04:54:46 INFO SparkEnv: Registering MapOutputTracker
25/05/19 04:54:46 INFO SparkEnv: Registering BlockManagerMaster
25/05/19 04:54:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/19 04:54:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/19 04:54:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/19 04:54:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1499aad7-58bd-4ca5-8fdc-54613b205b90
25/05/19 04:54:47 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/19 04:54:47 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/19 04:54:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/19 04:54:47 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b7392c33ae43:4040
25/05/19 04:54:47 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/19 04:54:47 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 30 ms (0 ms spent in bootstraps)
25/05/19 04:54:47 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250519045447-0009
25/05/19 04:54:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250519045447-0009/0 on worker-20250519032032-172.18.0.8-40663 (172.18.0.8:40663) with 8 core(s)
25/05/19 04:54:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20250519045447-0009/0 on hostPort 172.18.0.8:40663 with 8 core(s), 1024.0 MiB RAM
25/05/19 04:54:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41227.
25/05/19 04:54:47 INFO NettyBlockTransferService: Server created on b7392c33ae43:41227
25/05/19 04:54:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/19 04:54:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7392c33ae43, 41227, None)
25/05/19 04:54:47 INFO BlockManagerMasterEndpoint: Registering block manager b7392c33ae43:41227 with 366.3 MiB RAM, BlockManagerId(driver, b7392c33ae43, 41227, None)
25/05/19 04:54:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7392c33ae43, 41227, None)
25/05/19 04:54:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7392c33ae43, 41227, None)
25/05/19 04:54:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250519045447-0009/0 is now RUNNING
25/05/19 04:54:48 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/19 04:54:48 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/19 04:54:48 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/19 04:54:51 INFO InMemoryFileIndex: It took 111 ms to list leaf files for 1 paths.
25/05/19 04:54:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46558) with ID 0,  ResourceProfileId 0
25/05/19 04:54:51 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/05/19 04:54:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:46181 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 46181, None)
25/05/19 04:54:55 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:54:55 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/19 04:54:55 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:54:55 INFO CodeGenerator: Code generated in 261.091247 ms
25/05/19 04:54:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/19 04:54:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/19 04:54:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7392c33ae43:41227 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:54:56 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:54:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:54:56 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:54:56 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:54:56 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:54:56 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:54:56 INFO DAGScheduler: Missing parents: List()
25/05/19 04:54:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:54:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/19 04:54:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/19 04:54:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7392c33ae43:41227 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:54:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/19 04:54:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:54:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/19 04:54:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:54:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:46181 (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:54:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:46181 (size: 32.4 KiB, free: 366.3 MiB)
25/05/19 04:54:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3128 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:54:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/19 04:54:59 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.252 s
25/05/19 04:54:59 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:54:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/19 04:54:59 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.343173 s
25/05/19 04:54:59 INFO CodeGenerator: Code generated in 19.285866 ms
25/05/19 04:54:59 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:54:59 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:54:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:54:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/19 04:54:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/19 04:54:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7392c33ae43:41227 (size: 32.4 KiB, free: 366.2 MiB)
25/05/19 04:54:59 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:54:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:54:59 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/05/19 04:54:59 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7392c33ae43:41227 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/19 04:54:59 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:46181 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/05/19 04:54:59 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/05/19 04:54:59 INFO FileSourceStrategy: Pushed Filters: 
25/05/19 04:54:59 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/19 04:54:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/19 04:54:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/19 04:54:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/19 04:54:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b7392c33ae43:41227 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:54:59 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/19 04:54:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:54:59 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/19 04:54:59 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:54:59 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/19 04:54:59 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:54:59 INFO DAGScheduler: Missing parents: List()
25/05/19 04:54:59 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:54:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/19 04:55:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/19 04:55:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b7392c33ae43:41227 (size: 6.5 KiB, free: 366.2 MiB)
25/05/19 04:55:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/19 04:55:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:55:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/19 04:55:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:55:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:46181 (size: 6.5 KiB, free: 366.3 MiB)
25/05/19 04:55:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:46181 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:55:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 260 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:55:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/19 04:55:00 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.305 s
25/05/19 04:55:00 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:55:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/19 04:55:00 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.320092 s
25/05/19 04:55:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:55:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:55:01 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:55:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:55:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:55:01 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:55:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:55:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:55:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/19 04:55:01 INFO CodeGenerator: Code generated in 27.200995 ms
25/05/19 04:55:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.9 MiB)
25/05/19 04:55:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/05/19 04:55:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b7392c33ae43:41227 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:55:01 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:55:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:55:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:55:01 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:55:01 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:55:01 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:55:01 INFO DAGScheduler: Missing parents: List()
25/05/19 04:55:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:55:01 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/05/19 04:55:01 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/05/19 04:55:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on b7392c33ae43:41227 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:55:01 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/19 04:55:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:55:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/19 04:55:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:55:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:46181 (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:55:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:46181 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:55:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 329 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:55:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/19 04:55:01 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.345 s
25/05/19 04:55:01 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:55:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/19 04:55:01 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.352522 s
25/05/19 04:55:01 INFO CodeGenerator: Code generated in 17.458288 ms
25/05/19 04:55:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 362.8 MiB)
25/05/19 04:55:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.8 MiB)
25/05/19 04:55:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on b7392c33ae43:41227 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:55:01 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:55:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:55:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:55:01 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:55:02 INFO CodeGenerator: Code generated in 35.353344 ms
25/05/19 04:55:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.5 MiB)
25/05/19 04:55:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.4 MiB)
25/05/19 04:55:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on b7392c33ae43:41227 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:02 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/19 04:55:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:55:02 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/19 04:55:02 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:55:02 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/19 04:55:02 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:55:02 INFO DAGScheduler: Missing parents: List()
25/05/19 04:55:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:55:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.2 MiB)
25/05/19 04:55:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.2 MiB)
25/05/19 04:55:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on b7392c33ae43:41227 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:55:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/19 04:55:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:55:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/19 04:55:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:55:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:46181 (size: 75.9 KiB, free: 366.1 MiB)
25/05/19 04:55:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:46181 (size: 250.0 B, free: 366.1 MiB)
25/05/19 04:55:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:46181 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1220 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:55:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/19 04:55:03 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.265 s
25/05/19 04:55:03 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:55:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/19 04:55:03 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.274147 s
25/05/19 04:55:03 INFO FileFormatWriter: Start to commit write Job 00bdbd57-cac1-47d4-ac4d-7a5de4433421.
25/05/19 04:55:03 INFO FileFormatWriter: Write Job 00bdbd57-cac1-47d4-ac4d-7a5de4433421 committed. Elapsed time: 109 ms.
25/05/19 04:55:03 INFO FileFormatWriter: Finished processing stats for write job 00bdbd57-cac1-47d4-ac4d-7a5de4433421.
25/05/19 04:55:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/19 04:55:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/19 04:55:03 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/19 04:55:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:55:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:55:03 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:55:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:55:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:55:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:55:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:55:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/19 04:55:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/19 04:55:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/19 04:55:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 361.8 MiB)
25/05/19 04:55:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/05/19 04:55:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on b7392c33ae43:41227 (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:55:03 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:55:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:55:03 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:55:03 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/19 04:55:03 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/19 04:55:03 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:55:03 INFO DAGScheduler: Missing parents: List()
25/05/19 04:55:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/19 04:55:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 361.8 MiB)
25/05/19 04:55:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 361.8 MiB)
25/05/19 04:55:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on b7392c33ae43:41227 (size: 7.2 KiB, free: 366.0 MiB)
25/05/19 04:55:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/19 04:55:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/19 04:55:03 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/19 04:55:04 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b7392c33ae43:41227 in memory (size: 32.5 KiB, free: 366.0 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:46181 in memory (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:46181 (size: 7.2 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b7392c33ae43:41227 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:46181 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_8_piece0 on b7392c33ae43:41227 in memory (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.8:46181 in memory (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:46181 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on b7392c33ae43:41227 in memory (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.8:46181 in memory (size: 75.9 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 177 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_5_piece0 on b7392c33ae43:41227 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/19 04:55:04 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.226 s
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:46181 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:55:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/19 04:55:04 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.234997 s
25/05/19 04:55:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 361.2 MiB)
25/05/19 04:55:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 361.2 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on b7392c33ae43:41227 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:55:04 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/19 04:55:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/19 04:55:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/19 04:55:04 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on b7392c33ae43:41227 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.8:46181 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on b7392c33ae43:41227 in memory (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:46181 in memory (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:55:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/19 04:55:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on b7392c33ae43:41227 (size: 32.5 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:55:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/19 04:55:04 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/19 04:55:04 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/19 04:55:04 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/19 04:55:04 INFO DAGScheduler: Parents of final stage: List()
25/05/19 04:55:04 INFO DAGScheduler: Missing parents: List()
25/05/19 04:55:04 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/19 04:55:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/19 04:55:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 362.5 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on b7392c33ae43:41227 (size: 76.0 KiB, free: 366.1 MiB)
25/05/19 04:55:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/19 04:55:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/19 04:55:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/19 04:55:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:46181 (size: 76.0 KiB, free: 366.2 MiB)
25/05/19 04:55:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:46181 (size: 250.0 B, free: 366.2 MiB)
25/05/19 04:55:05 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:46181 (size: 32.5 KiB, free: 366.1 MiB)
25/05/19 04:55:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2363 ms on 172.18.0.8 (executor 0) (1/1)
25/05/19 04:55:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/19 04:55:06 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 2.405 s
25/05/19 04:55:06 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/19 04:55:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/19 04:55:06 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 2.412533 s
25/05/19 04:55:06 INFO FileFormatWriter: Start to commit write Job 2f178989-d59b-4b7b-9cef-09e617eba0a3.
25/05/19 04:55:06 INFO FileFormatWriter: Write Job 2f178989-d59b-4b7b-9cef-09e617eba0a3 committed. Elapsed time: 60 ms.
25/05/19 04:55:06 INFO FileFormatWriter: Finished processing stats for write job 2f178989-d59b-4b7b-9cef-09e617eba0a3.
Job completed for 2025-01-01
25/05/19 04:55:06 INFO SparkUI: Stopped Spark web UI at http://b7392c33ae43:4040
25/05/19 04:55:06 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/19 04:55:06 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/19 04:55:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/19 04:55:06 INFO MemoryStore: MemoryStore cleared
25/05/19 04:55:06 INFO BlockManager: BlockManager stopped
25/05/19 04:55:06 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/19 04:55:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/19 04:55:07 INFO SparkContext: Successfully stopped SparkContext
25/05/19 04:55:07 INFO ShutdownHookManager: Shutdown hook called
25/05/19 04:55:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-a1911fe7-d8a0-459c-ae4a-34393d284740/pyspark-20cb3083-e16d-4863-b3ec-58214ffac625
25/05/19 04:55:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-da12bc81-00ef-4657-84fc-681d6215f4df
25/05/19 04:55:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-a1911fe7-d8a0-459c-ae4a-34393d284740
Job completed for 2025-01-01
Triggering sales_etl.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/21 03:19:06 INFO SparkContext: Running Spark version 3.2.1
25/05/21 03:19:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/21 03:19:07 INFO ResourceUtils: ==============================================================
25/05/21 03:19:07 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/21 03:19:07 INFO ResourceUtils: ==============================================================
25/05/21 03:19:07 INFO SparkContext: Submitted application: SalesETLJob
25/05/21 03:19:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/21 03:19:07 INFO ResourceProfile: Limiting resource is cpu
25/05/21 03:19:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/21 03:19:07 INFO SecurityManager: Changing view acls to: spark
25/05/21 03:19:07 INFO SecurityManager: Changing modify acls to: spark
25/05/21 03:19:07 INFO SecurityManager: Changing view acls groups to: 
25/05/21 03:19:07 INFO SecurityManager: Changing modify acls groups to: 
25/05/21 03:19:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/21 03:19:08 INFO Utils: Successfully started service 'sparkDriver' on port 37431.
25/05/21 03:19:08 INFO SparkEnv: Registering MapOutputTracker
25/05/21 03:19:08 INFO SparkEnv: Registering BlockManagerMaster
25/05/21 03:19:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/21 03:19:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/21 03:19:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/21 03:19:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-34bd8205-c2bc-4fc9-bed7-9279e5e66187
25/05/21 03:19:08 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/21 03:19:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/21 03:19:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/21 03:19:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3263e45d63a6:4040
25/05/21 03:19:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/21 03:19:09 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 72 ms (0 ms spent in bootstraps)
25/05/21 03:19:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250521031910-0001
25/05/21 03:19:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250521031910-0001/0 on worker-20250521031438-172.18.0.5-41655 (172.18.0.5:41655) with 8 core(s)
25/05/21 03:19:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20250521031910-0001/0 on hostPort 172.18.0.5:41655 with 8 core(s), 1024.0 MiB RAM
25/05/21 03:19:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37477.
25/05/21 03:19:10 INFO NettyBlockTransferService: Server created on 3263e45d63a6:37477
25/05/21 03:19:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/21 03:19:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3263e45d63a6, 37477, None)
25/05/21 03:19:10 INFO BlockManagerMasterEndpoint: Registering block manager 3263e45d63a6:37477 with 366.3 MiB RAM, BlockManagerId(driver, 3263e45d63a6, 37477, None)
25/05/21 03:19:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3263e45d63a6, 37477, None)
25/05/21 03:19:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3263e45d63a6, 37477, None)
25/05/21 03:19:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250521031910-0001/0 is now RUNNING
25/05/21 03:19:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/21 03:19:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/21 03:19:13 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/21 03:19:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:58600) with ID 0,  ResourceProfileId 0
25/05/21 03:19:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:44995 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.5, 44995, None)
25/05/21 03:19:18 INFO InMemoryFileIndex: It took 292 ms to list leaf files for 1 paths.
25/05/21 03:19:18 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
25/05/21 03:19:25 INFO FileSourceStrategy: Pushed Filters: 
25/05/21 03:19:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/21 03:19:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/21 03:19:27 INFO CodeGenerator: Code generated in 471.288786 ms
25/05/21 03:19:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/21 03:19:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/21 03:19:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3263e45d63a6:37477 (size: 32.4 KiB, free: 366.3 MiB)
25/05/21 03:19:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/21 03:19:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/21 03:19:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:19:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/21 03:19:27 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:19:27 INFO DAGScheduler: Missing parents: List()
25/05/21 03:19:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:19:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/21 03:19:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/21 03:19:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3263e45d63a6:37477 (size: 5.8 KiB, free: 366.3 MiB)
25/05/21 03:19:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/21 03:19:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:19:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/21 03:19:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/21 03:19:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:44995 (size: 5.8 KiB, free: 366.3 MiB)
25/05/21 03:19:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:44995 (size: 32.4 KiB, free: 366.3 MiB)
25/05/21 03:19:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 6328 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:19:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/21 03:19:34 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 6.592 s
25/05/21 03:19:34 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:19:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/21 03:19:34 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 6.555812 s
25/05/21 03:19:34 INFO CodeGenerator: Code generated in 41.637911 ms
25/05/21 03:19:34 INFO FileSourceStrategy: Pushed Filters: 
25/05/21 03:19:34 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/21 03:19:34 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/21 03:19:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/21 03:19:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/21 03:19:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3263e45d63a6:37477 (size: 32.4 KiB, free: 366.2 MiB)
25/05/21 03:19:34 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/21 03:19:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:34 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/05/21 03:19:34 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/05/21 03:19:35 INFO FileSourceStrategy: Pushed Filters: 
25/05/21 03:19:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/21 03:19:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/21 03:19:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/21 03:19:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/21 03:19:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3263e45d63a6:37477 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:19:35 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/21 03:19:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:35 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/21 03:19:35 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:19:35 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/21 03:19:35 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:19:35 INFO DAGScheduler: Missing parents: List()
25/05/21 03:19:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:19:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/21 03:19:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/21 03:19:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3263e45d63a6:37477 (size: 6.5 KiB, free: 366.2 MiB)
25/05/21 03:19:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/21 03:19:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:19:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/21 03:19:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.5, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/21 03:19:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:44995 (size: 6.5 KiB, free: 366.3 MiB)
25/05/21 03:19:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:44995 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:19:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 433 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:19:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/21 03:19:35 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.502 s
25/05/21 03:19:35 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:19:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/21 03:19:35 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.519069 s
25/05/21 03:19:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3263e45d63a6:37477 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/21 03:19:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:44995 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/21 03:19:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 3263e45d63a6:37477 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:19:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:44995 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/21 03:19:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3263e45d63a6:37477 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/21 03:19:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:44995 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/05/21 03:19:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/21 03:19:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/21 03:19:37 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/21 03:19:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:19:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:19:37 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:19:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/21 03:19:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/21 03:19:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/21 03:19:37 INFO CodeGenerator: Code generated in 36.597193 ms
25/05/21 03:19:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/05/21 03:19:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/21 03:19:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3263e45d63a6:37477 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:19:37 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:19:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:37 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:19:37 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/21 03:19:37 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/21 03:19:37 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:19:37 INFO DAGScheduler: Missing parents: List()
25/05/21 03:19:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/21 03:19:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/21 03:19:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/21 03:19:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3263e45d63a6:37477 (size: 7.2 KiB, free: 366.2 MiB)
25/05/21 03:19:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/21 03:19:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/21 03:19:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/21 03:19:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.5, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/21 03:19:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:44995 (size: 7.2 KiB, free: 366.3 MiB)
25/05/21 03:19:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:44995 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:19:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 842 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:19:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/21 03:19:38 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.877 s
25/05/21 03:19:38 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:19:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/21 03:19:38 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.890128 s
25/05/21 03:19:38 INFO CodeGenerator: Code generated in 47.266186 ms
25/05/21 03:19:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/21 03:19:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/21 03:19:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3263e45d63a6:37477 (size: 250.0 B, free: 366.2 MiB)
25/05/21 03:19:39 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:19:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:19:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:19:39 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:19:39 INFO CodeGenerator: Code generated in 65.958307 ms
25/05/21 03:19:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/21 03:19:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/21 03:19:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3263e45d63a6:37477 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:19:39 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/21 03:19:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:39 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/21 03:19:39 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:19:39 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/21 03:19:39 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:19:39 INFO DAGScheduler: Missing parents: List()
25/05/21 03:19:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:19:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/21 03:19:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/21 03:19:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3263e45d63a6:37477 (size: 75.9 KiB, free: 366.1 MiB)
25/05/21 03:19:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/21 03:19:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:19:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/21 03:19:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.5, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/21 03:19:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:44995 (size: 75.9 KiB, free: 366.2 MiB)
25/05/21 03:19:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:44995 (size: 250.0 B, free: 366.2 MiB)
25/05/21 03:19:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:44995 (size: 32.5 KiB, free: 366.1 MiB)
25/05/21 03:19:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1699 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:19:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/21 03:19:41 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.809 s
25/05/21 03:19:41 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:19:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/21 03:19:41 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.832178 s
25/05/21 03:19:41 INFO FileFormatWriter: Start to commit write Job fdbc8895-a107-4bd7-aa5f-4e9b1df82f83.
25/05/21 03:19:41 INFO FileFormatWriter: Write Job fdbc8895-a107-4bd7-aa5f-4e9b1df82f83 committed. Elapsed time: 434 ms.
25/05/21 03:19:41 INFO FileFormatWriter: Finished processing stats for write job fdbc8895-a107-4bd7-aa5f-4e9b1df82f83.
25/05/21 03:19:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/21 03:19:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/21 03:19:42 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/21 03:19:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:19:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:19:42 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:19:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/21 03:19:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/21 03:19:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/21 03:19:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/21 03:19:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/21 03:19:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/21 03:19:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/21 03:19:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/21 03:19:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/21 03:19:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3263e45d63a6:37477 (size: 32.5 KiB, free: 366.1 MiB)
25/05/21 03:19:42 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:19:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:42 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:19:42 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/21 03:19:42 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/21 03:19:42 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:19:42 INFO DAGScheduler: Missing parents: List()
25/05/21 03:19:42 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/21 03:19:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/21 03:19:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/21 03:19:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 3263e45d63a6:37477 (size: 7.2 KiB, free: 366.1 MiB)
25/05/21 03:19:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/21 03:19:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/21 03:19:42 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/21 03:19:42 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.5, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/21 03:19:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:44995 (size: 7.2 KiB, free: 366.1 MiB)
25/05/21 03:19:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:44995 (size: 32.5 KiB, free: 366.1 MiB)
25/05/21 03:19:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 395 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:19:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/21 03:19:43 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.431 s
25/05/21 03:19:43 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:19:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/21 03:19:43 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.476217 s
25/05/21 03:19:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/21 03:19:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/21 03:19:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 3263e45d63a6:37477 (size: 250.0 B, free: 366.1 MiB)
25/05/21 03:19:43 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:19:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:19:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:19:43 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:19:43 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/21 03:19:43 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/21 03:19:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 3263e45d63a6:37477 (size: 32.5 KiB, free: 366.0 MiB)
25/05/21 03:19:43 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/21 03:19:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:19:43 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/21 03:19:43 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:19:43 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/21 03:19:43 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:19:43 INFO DAGScheduler: Missing parents: List()
25/05/21 03:19:43 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:19:43 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/21 03:19:43 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/21 03:19:43 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 3263e45d63a6:37477 (size: 76.0 KiB, free: 365.9 MiB)
25/05/21 03:19:43 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/21 03:19:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:19:43 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/21 03:19:43 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.5, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/21 03:19:43 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:44995 (size: 76.0 KiB, free: 366.0 MiB)
25/05/21 03:19:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:44995 (size: 250.0 B, free: 366.0 MiB)
25/05/21 03:19:45 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:44995 (size: 32.5 KiB, free: 366.0 MiB)
25/05/21 03:19:46 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 3115 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:19:46 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/21 03:19:46 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 3.200 s
25/05/21 03:19:46 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:19:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/21 03:19:46 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 3.209936 s
25/05/21 03:19:46 INFO FileFormatWriter: Start to commit write Job 1a72e688-9dbc-480d-a1da-4507964ee4af.
25/05/21 03:19:46 INFO FileFormatWriter: Write Job 1a72e688-9dbc-480d-a1da-4507964ee4af committed. Elapsed time: 96 ms.
25/05/21 03:19:46 INFO FileFormatWriter: Finished processing stats for write job 1a72e688-9dbc-480d-a1da-4507964ee4af.
Job completed for 2025-01-01
25/05/21 03:19:46 INFO SparkUI: Stopped Spark web UI at http://3263e45d63a6:4040
25/05/21 03:19:46 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/21 03:19:46 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/21 03:19:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/21 03:19:47 INFO MemoryStore: MemoryStore cleared
25/05/21 03:19:47 INFO BlockManager: BlockManager stopped
25/05/21 03:19:47 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/21 03:19:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/21 03:19:47 INFO SparkContext: Successfully stopped SparkContext
25/05/21 03:19:47 INFO ShutdownHookManager: Shutdown hook called
25/05/21 03:19:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-b0ae4459-3978-4213-8c2b-2e6af76b81c9
25/05/21 03:19:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-bdf4ef0f-803b-44e0-965e-b66de0fce078/pyspark-557c06aa-bf8a-41ea-92a2-46111555b0d5
25/05/21 03:19:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-bdf4ef0f-803b-44e0-965e-b66de0fce078
Job completed for 2025-01-01
Triggering sales_etl.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/05/21 03:20:05 INFO SparkContext: Running Spark version 3.2.1
25/05/21 03:20:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/21 03:20:05 INFO ResourceUtils: ==============================================================
25/05/21 03:20:05 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/21 03:20:05 INFO ResourceUtils: ==============================================================
25/05/21 03:20:05 INFO SparkContext: Submitted application: SalesETLJob
25/05/21 03:20:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/21 03:20:06 INFO ResourceProfile: Limiting resource is cpu
25/05/21 03:20:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/21 03:20:06 INFO SecurityManager: Changing view acls to: spark
25/05/21 03:20:06 INFO SecurityManager: Changing modify acls to: spark
25/05/21 03:20:06 INFO SecurityManager: Changing view acls groups to: 
25/05/21 03:20:06 INFO SecurityManager: Changing modify acls groups to: 
25/05/21 03:20:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/05/21 03:20:06 INFO Utils: Successfully started service 'sparkDriver' on port 39563.
25/05/21 03:20:06 INFO SparkEnv: Registering MapOutputTracker
25/05/21 03:20:06 INFO SparkEnv: Registering BlockManagerMaster
25/05/21 03:20:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/21 03:20:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/21 03:20:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/21 03:20:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-73d7675b-dac8-486e-b467-f0bdb991326a
25/05/21 03:20:06 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/05/21 03:20:06 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/21 03:20:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/21 03:20:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3263e45d63a6:4040
25/05/21 03:20:08 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/21 03:20:08 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 75 ms (0 ms spent in bootstraps)
25/05/21 03:20:08 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250521032008-0002
25/05/21 03:20:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250521032008-0002/0 on worker-20250521031438-172.18.0.5-41655 (172.18.0.5:41655) with 8 core(s)
25/05/21 03:20:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250521032008-0002/0 on hostPort 172.18.0.5:41655 with 8 core(s), 1024.0 MiB RAM
25/05/21 03:20:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35313.
25/05/21 03:20:08 INFO NettyBlockTransferService: Server created on 3263e45d63a6:35313
25/05/21 03:20:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/21 03:20:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3263e45d63a6, 35313, None)
25/05/21 03:20:08 INFO BlockManagerMasterEndpoint: Registering block manager 3263e45d63a6:35313 with 366.3 MiB RAM, BlockManagerId(driver, 3263e45d63a6, 35313, None)
25/05/21 03:20:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3263e45d63a6, 35313, None)
25/05/21 03:20:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3263e45d63a6, 35313, None)
25/05/21 03:20:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250521032008-0002/0 is now RUNNING
25/05/21 03:20:09 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/21 03:20:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/21 03:20:10 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/21 03:20:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:34826) with ID 0,  ResourceProfileId 0
25/05/21 03:20:16 INFO InMemoryFileIndex: It took 214 ms to list leaf files for 1 paths.
25/05/21 03:20:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:36471 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.5, 36471, None)
25/05/21 03:20:16 INFO InMemoryFileIndex: It took 30 ms to list leaf files for 1 paths.
25/05/21 03:20:21 INFO FileSourceStrategy: Pushed Filters: 
25/05/21 03:20:21 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/21 03:20:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/21 03:20:23 INFO CodeGenerator: Code generated in 493.421792 ms
25/05/21 03:20:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/05/21 03:20:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/05/21 03:20:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3263e45d63a6:35313 (size: 32.4 KiB, free: 366.3 MiB)
25/05/21 03:20:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/05/21 03:20:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/21 03:20:23 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:20:23 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/05/21 03:20:23 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:20:23 INFO DAGScheduler: Missing parents: List()
25/05/21 03:20:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:20:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/05/21 03:20:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/05/21 03:20:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3263e45d63a6:35313 (size: 5.8 KiB, free: 366.3 MiB)
25/05/21 03:20:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/05/21 03:20:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:20:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/21 03:20:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/21 03:20:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:36471 (size: 5.8 KiB, free: 366.3 MiB)
25/05/21 03:20:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:36471 (size: 32.4 KiB, free: 366.3 MiB)
25/05/21 03:20:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4869 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:20:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/21 03:20:28 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.187 s
25/05/21 03:20:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:20:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/21 03:20:28 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.279248 s
25/05/21 03:20:29 INFO CodeGenerator: Code generated in 28.919227 ms
25/05/21 03:20:29 INFO FileSourceStrategy: Pushed Filters: 
25/05/21 03:20:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/21 03:20:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/21 03:20:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/05/21 03:20:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/05/21 03:20:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3263e45d63a6:35313 (size: 32.4 KiB, free: 366.2 MiB)
25/05/21 03:20:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/05/21 03:20:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:29 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
25/05/21 03:20:29 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/05/21 03:20:29 INFO FileSourceStrategy: Pushed Filters: 
25/05/21 03:20:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/05/21 03:20:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/05/21 03:20:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/05/21 03:20:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/05/21 03:20:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3263e45d63a6:35313 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:20:29 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/05/21 03:20:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:29 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/05/21 03:20:29 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:20:29 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/05/21 03:20:29 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:20:29 INFO DAGScheduler: Missing parents: List()
25/05/21 03:20:29 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:20:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/05/21 03:20:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/05/21 03:20:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3263e45d63a6:35313 (size: 6.5 KiB, free: 366.2 MiB)
25/05/21 03:20:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/05/21 03:20:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:20:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/21 03:20:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.5, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/21 03:20:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:36471 (size: 6.5 KiB, free: 366.3 MiB)
25/05/21 03:20:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:36471 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:20:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 461 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:20:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/21 03:20:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.542 s
25/05/21 03:20:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:20:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/21 03:20:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.559150 s
25/05/21 03:20:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/21 03:20:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/21 03:20:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/21 03:20:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:20:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:20:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:20:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/21 03:20:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/21 03:20:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/05/21 03:20:32 INFO CodeGenerator: Code generated in 40.95732 ms
25/05/21 03:20:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/05/21 03:20:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/05/21 03:20:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3263e45d63a6:35313 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:20:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:20:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3263e45d63a6:35313 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/21 03:20:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:36471 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/05/21 03:20:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:20:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 3263e45d63a6:35313 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:20:32 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/21 03:20:32 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/21 03:20:32 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:20:32 INFO DAGScheduler: Missing parents: List()
25/05/21 03:20:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/21 03:20:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:36471 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/05/21 03:20:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/05/21 03:20:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/05/21 03:20:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3263e45d63a6:35313 (size: 7.2 KiB, free: 366.2 MiB)
25/05/21 03:20:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3263e45d63a6:35313 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/05/21 03:20:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/05/21 03:20:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/21 03:20:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/21 03:20:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:36471 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/05/21 03:20:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.5, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/21 03:20:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:36471 (size: 7.2 KiB, free: 366.3 MiB)
25/05/21 03:20:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:36471 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:20:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 560 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:20:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/21 03:20:33 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.611 s
25/05/21 03:20:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:20:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/21 03:20:33 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.637085 s
25/05/21 03:20:33 INFO CodeGenerator: Code generated in 23.745281 ms
25/05/21 03:20:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 MiB, free 363.2 MiB)
25/05/21 03:20:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.2 MiB)
25/05/21 03:20:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3263e45d63a6:35313 (size: 250.0 B, free: 366.2 MiB)
25/05/21 03:20:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:20:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:20:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:20:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:20:33 INFO CodeGenerator: Code generated in 117.771014 ms
25/05/21 03:20:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 362.9 MiB)
25/05/21 03:20:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.8 MiB)
25/05/21 03:20:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3263e45d63a6:35313 (size: 32.5 KiB, free: 366.2 MiB)
25/05/21 03:20:33 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/05/21 03:20:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/05/21 03:20:34 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:20:34 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/05/21 03:20:34 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:20:34 INFO DAGScheduler: Missing parents: List()
25/05/21 03:20:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:20:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 362.6 MiB)
25/05/21 03:20:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 362.5 MiB)
25/05/21 03:20:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3263e45d63a6:35313 (size: 75.9 KiB, free: 366.1 MiB)
25/05/21 03:20:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/05/21 03:20:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:20:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/21 03:20:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.5, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/21 03:20:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:36471 (size: 75.9 KiB, free: 366.2 MiB)
25/05/21 03:20:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:36471 (size: 250.0 B, free: 366.2 MiB)
25/05/21 03:20:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:36471 (size: 32.5 KiB, free: 366.1 MiB)
25/05/21 03:20:35 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1462 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:20:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/21 03:20:35 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.758 s
25/05/21 03:20:35 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:20:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/21 03:20:35 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.666913 s
25/05/21 03:20:35 INFO FileFormatWriter: Start to commit write Job 9282e572-cdce-4f93-ab73-f25a0d8ce62d.
25/05/21 03:20:35 INFO FileFormatWriter: Write Job 9282e572-cdce-4f93-ab73-f25a0d8ce62d committed. Elapsed time: 164 ms.
25/05/21 03:20:35 INFO FileFormatWriter: Finished processing stats for write job 9282e572-cdce-4f93-ab73-f25a0d8ce62d.
25/05/21 03:20:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/05/21 03:20:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/05/21 03:20:36 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/05/21 03:20:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:20:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:20:36 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:20:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/21 03:20:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/21 03:20:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/21 03:20:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/21 03:20:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/21 03:20:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/21 03:20:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 362.2 MiB)
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 362.2 MiB)
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3263e45d63a6:35313 (size: 32.5 KiB, free: 366.1 MiB)
25/05/21 03:20:36 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:20:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:20:36 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/05/21 03:20:36 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/05/21 03:20:36 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:20:36 INFO DAGScheduler: Missing parents: List()
25/05/21 03:20:36 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 362.2 MiB)
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 362.2 MiB)
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 3263e45d63a6:35313 (size: 7.2 KiB, free: 366.1 MiB)
25/05/21 03:20:36 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/05/21 03:20:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/05/21 03:20:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/21 03:20:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.5, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:36471 (size: 7.2 KiB, free: 366.1 MiB)
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:36471 (size: 32.5 KiB, free: 366.1 MiB)
25/05/21 03:20:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 167 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:20:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/21 03:20:36 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.192 s
25/05/21 03:20:36 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:20:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/21 03:20:36 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.208801 s
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.0 MiB, free 360.2 MiB)
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 360.2 MiB)
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 3263e45d63a6:35313 (size: 250.0 B, free: 366.1 MiB)
25/05/21 03:20:36 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/05/21 03:20:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/05/21 03:20:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/05/21 03:20:36 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 359.8 MiB)
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 359.8 MiB)
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 3263e45d63a6:35313 (size: 32.5 KiB, free: 366.0 MiB)
25/05/21 03:20:36 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/05/21 03:20:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/21 03:20:36 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/05/21 03:20:36 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/05/21 03:20:36 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/05/21 03:20:36 INFO DAGScheduler: Parents of final stage: List()
25/05/21 03:20:36 INFO DAGScheduler: Missing parents: List()
25/05/21 03:20:36 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 359.6 MiB)
25/05/21 03:20:36 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 359.5 MiB)
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 3263e45d63a6:35313 (size: 76.0 KiB, free: 365.9 MiB)
25/05/21 03:20:36 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/05/21 03:20:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/05/21 03:20:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/21 03:20:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.5, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/05/21 03:20:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:36471 (size: 76.0 KiB, free: 366.0 MiB)
25/05/21 03:20:37 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:36471 (size: 250.0 B, free: 366.0 MiB)
25/05/21 03:20:38 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:36471 (size: 32.5 KiB, free: 366.0 MiB)
25/05/21 03:20:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1857 ms on 172.18.0.5 (executor 0) (1/1)
25/05/21 03:20:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/21 03:20:38 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.903 s
25/05/21 03:20:38 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/21 03:20:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/21 03:20:38 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.914077 s
25/05/21 03:20:38 INFO FileFormatWriter: Start to commit write Job e62544f5-3650-4fb0-95d7-abe9549c1828.
25/05/21 03:20:38 INFO FileFormatWriter: Write Job e62544f5-3650-4fb0-95d7-abe9549c1828 committed. Elapsed time: 53 ms.
25/05/21 03:20:38 INFO FileFormatWriter: Finished processing stats for write job e62544f5-3650-4fb0-95d7-abe9549c1828.
Job completed for 2025-01-01
25/05/21 03:20:38 INFO SparkUI: Stopped Spark web UI at http://3263e45d63a6:4040
25/05/21 03:20:38 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/21 03:20:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/05/21 03:20:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/21 03:20:39 INFO MemoryStore: MemoryStore cleared
25/05/21 03:20:39 INFO BlockManager: BlockManager stopped
25/05/21 03:20:39 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/21 03:20:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/21 03:20:39 INFO SparkContext: Successfully stopped SparkContext
25/05/21 03:20:39 INFO ShutdownHookManager: Shutdown hook called
25/05/21 03:20:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-5c2e6d4a-b47e-41cd-baa3-99b60a4e256a
25/05/21 03:20:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-a81e8daa-6c96-430d-9044-7eb91b32b400
25/05/21 03:20:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-5c2e6d4a-b47e-41cd-baa3-99b60a4e256a/pyspark-d469e0b8-bed3-44a2-85e3-54c266a065e2
Job completed for 2025-01-01
